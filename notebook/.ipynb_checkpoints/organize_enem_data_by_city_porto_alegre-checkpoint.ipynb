{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remoções prontas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "filepath = r'C:\\Users\\Luis_Dutra\\3D Objects\\datasets\\enem\\MICRODADOS_ENEM_2019.csv'\n",
    "\n",
    "# Ler quantidade determinada de linhas do dataset\n",
    "#df = pd.read_csv(filepath, encoding='iso8859-1', sep = ';', nrows = 100000000)\n",
    "df = pd.read_csv(filepath, encoding='iso8859-1', sep = ';')\n",
    "\n",
    "# Deletando colunas dispensáveis do dataframe\n",
    "del df['NO_MUNICIPIO_NASCIMENTO']\n",
    "del df['CO_PROVA_CN']\n",
    "del df['CO_PROVA_CH']\n",
    "del df['CO_PROVA_LC']\n",
    "del df['CO_PROVA_MT']\n",
    "del df['NU_ANO']\n",
    "del df['CO_MUNICIPIO_RESIDENCIA']\n",
    "del df['CO_UF_RESIDENCIA']\n",
    "del df['CO_MUNICIPIO_NASCIMENTO']\n",
    "del df['CO_UF_NASCIMENTO']\n",
    "del df['CO_ESCOLA']\n",
    "del df['CO_MUNICIPIO_ESC']\n",
    "del df['CO_UF_ESC']\n",
    "del df['CO_MUNICIPIO_PROVA']\n",
    "del df['CO_UF_PROVA']\n",
    "del df['TX_RESPOSTAS_CN']\n",
    "del df['TX_RESPOSTAS_CH']\n",
    "del df['TX_RESPOSTAS_LC']\n",
    "del df['TX_RESPOSTAS_MT']\n",
    "del df['TX_GABARITO_CN']\n",
    "del df['TX_GABARITO_CH']\n",
    "del df['TX_GABARITO_LC']\n",
    "del df['TX_GABARITO_MT']\n",
    "del df['Q003']\n",
    "del df['Q004']\n",
    "del df['Q005']\n",
    "del df['Q007']\n",
    "del df['Q008']\n",
    "del df['Q009']\n",
    "del df['Q010']\n",
    "del df['Q011']\n",
    "del df['Q012']\n",
    "del df['Q013']\n",
    "del df['Q014']\n",
    "del df['Q015']\n",
    "del df['Q016']\n",
    "del df['Q017']\n",
    "del df['Q018']\n",
    "del df['Q019']\n",
    "del df['Q020']\n",
    "del df['Q021']\n",
    "del df['Q022']\n",
    "del df['Q023']\n",
    "del df['Q024']\n",
    "del df[\"IN_BAIXA_VISAO\"]\n",
    "del df[\"IN_NOME_SOCIAL\"]\n",
    "del df[\"IN_SALA_INDIVIDUAL\"]\n",
    "del df[\"IN_SALA_ESPECIAL\"]\n",
    "del df[\"IN_SALA_ACOMPANHANTE\"]\n",
    "del df[\"IN_MOBILIARIO_ESPECIFICO\"]\n",
    "del df[\"IN_MATERIAL_ESPECIFICO\"]\n",
    "del df[\"IN_DEFICIENCIA_AUDITIVA\"]\n",
    "del df[\"IN_VISAO_MONOCULAR\"]\n",
    "del df[\"IN_OUTRA_DEF\"]\n",
    "del df[\"IN_LACTANTE\"]\n",
    "del df[\"IN_ESTUDA_CLASSE_HOSPITALAR\"]\n",
    "del df[\"IN_SEM_RECURSO\"]\n",
    "del df[\"IN_BRAILLE\"]\n",
    "del df[\"IN_AMPLIADA_24\"]\n",
    "del df[\"IN_AMPLIADA_18\"]\n",
    "del df[\"IN_LEDOR\"]\n",
    "del df[\"IN_ACESSO\"]\n",
    "del df[\"IN_TRANSCRICAO\"]\n",
    "del df[\"IN_LIBRAS\"]\n",
    "del df[\"IN_TEMPO_ADICIONAL\"]\n",
    "del df[\"IN_LEITURA_LABIAL\"]\n",
    "del df[\"IN_MESA_CADEIRA_RODAS\"]\n",
    "del df[\"IN_MESA_CADEIRA_SEPARADA\"]\n",
    "del df[\"IN_APOIO_PERNA\"]\n",
    "del df[\"IN_GUIA_INTERPRETE\"]\n",
    "del df[\"IN_COMPUTADOR\"]\n",
    "del df[\"IN_CADEIRA_ESPECIAL\"]\n",
    "del df[\"IN_CADEIRA_CANHOTO\"]\n",
    "del df[\"IN_CADEIRA_ACOLCHOADA\"]\n",
    "del df[\"IN_PROVA_DEITADO\"]\n",
    "del df[\"IN_MOBILIARIO_OBESO\"]\n",
    "del df[\"IN_LAMINA_OVERLAY\"]\n",
    "del df[\"IN_PROTETOR_AURICULAR\"]\n",
    "del df[\"IN_MEDIDOR_GLICOSE\"]\n",
    "del df[\"IN_MAQUINA_BRAILE\"]\n",
    "del df[\"IN_SOROBAN\"]\n",
    "del df[\"IN_MARCA_PASSO\"]\n",
    "del df[\"IN_SONDA\"]\n",
    "del df[\"IN_MEDICAMENTOS\"]\n",
    "del df['NU_NOTA_COMP1']\n",
    "del df['NU_NOTA_COMP2']\n",
    "del df['NU_NOTA_COMP3']\n",
    "del df['NU_NOTA_COMP4']\n",
    "del df['NU_NOTA_COMP5']\n",
    "\n",
    "print(\"Remoções prontas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaces prontos\n"
     ]
    }
   ],
   "source": [
    "# Os valores do dataset foram substituidos pelos seus reais significados do dicionário\n",
    "# df[\"column_name\"].replace({0:\"\", 1:\"\", 2:\"\", 3:\"\", 4:\"\"}, inplace=True)\n",
    "# Trocando alguns valores inteiros do data set pelo seus reais significados\n",
    "\n",
    "df[\"TP_ESTADO_CIVIL\"].replace({0:\"Não informado\", 1:\"Solteiro(a)\", 2:\"Casado(a)/Mora com companheiro(a)\", 3:\"Divorciado(a)/Desquitado(a)/Separado(a)\", 4:\"Viúvo(a)\"}, inplace=True)\n",
    "df[\"TP_COR_RACA\"].replace({0:\"Não declarado\", 1:\"Branca\", 2:\"Preta\", 3:\"Parda\", 4:\"Amarela\", 5:\"Indígena\"}, inplace=True)\n",
    "df[\"TP_NACIONALIDADE\"].replace({0:\"Não informado\", 1:\"Brasileiro(a)\", 2:\"Brasileiro(a) Naturalizado(a)\", 3:\"Estrangeiro(a)\", 4:\"Brasileiro(a) Nato(a), nascido(a) no exterior\"}, inplace=True)\n",
    "df[\"TP_ST_CONCLUSAO\"].replace({1:\"Já concluí o Ensino Médio\", 2:\"Estou cursando e concluirei o Ensino Médio em 2019\", 3:\"Estou cursando e concluirei o Ensino Médio após 2019\", 4:\"Não concluí e não estou cursando o Ensino Médio\"}, inplace=True)\n",
    "df[\"TP_ANO_CONCLUIU\"].replace({0:\"Não informado\", 1:\"2018\", 2:\"2017\", 3 :\"2016\", 4:\"2015\", 5:\"2014\", 6:\"2013\", 7:\"2012\", 8:\"2011\", 9:\"2010\", 10:\"2009\", 11:\"2008\", 12:\"2007\", 13:\"Antes de 2007\"}, inplace=True)\n",
    "df[\"TP_ESCOLA\"].replace({1:\"Não Respondeu\", 2:\"Pública\", 3:\"Privada\", 4:\"Exterior\"}, inplace=True)\n",
    "df[\"TP_ENSINO\"].replace({1:\"Ensino Regular\", 2:\"Educação Especial - Modalidade Substitutiva\", 3:\"Educação de Jovens e Adultos\"}, inplace=True)\n",
    "df[\"IN_TREINEIRO\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"TP_DEPENDENCIA_ADM_ESC\"].replace({1:\"Federal\", 2:\"Estadual\", 3:\"Municipal\", 4:\"Privada\"}, inplace=True)\n",
    "df[\"TP_LOCALIZACAO_ESC\"].replace({1:\"Urbana\", 2:\"Rural\"}, inplace=True)\n",
    "df[\"TP_SIT_FUNC_ESC\"].replace({1:\"Em atividade\", 2:\"Paralisada\", 3:\"Extinta\"}, inplace=True)\n",
    "df[\"IN_CEGUEIRA\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_SURDEZ\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_IDOSO\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_GESTANTE\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_DEFICIENCIA_FISICA\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_DEFICIENCIA_MENTAL\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_DEFICIT_ATENCAO\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_DISLEXIA\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_DISCALCULIA\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_AUTISMO\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"IN_SURDO_CEGUEIRA\"].replace({1:\"Sim\", 0:\"Não\"}, inplace=True)\n",
    "df[\"TP_PRESENCA_CN\"].replace({0:\"Faltou à prova\", 1:\"Presente na prova\", 2:\"Eliminado na Prova\"}, inplace=True)\n",
    "df[\"TP_PRESENCA_CH\"].replace({0:\"Faltou à prova\", 1:\"Presente na prova\", 2:\"Eliminado na Prova\"}, inplace=True) \n",
    "df[\"TP_PRESENCA_LC\"].replace({0:\"Faltou à prova\", 1:\"Presente na prova\", 2:\"Eliminado na Prova\"}, inplace=True) \n",
    "df[\"TP_PRESENCA_MT\"].replace({0:\"Faltou à prova\", 1:\"Presente na prova\", 2:\"Eliminado na Prova\"}, inplace=True)\n",
    "df[\"TP_LINGUA\"].replace({0:\"Inglês\", 1:\"Espanhol\"}, inplace=True)\n",
    "df[\"TP_STATUS_REDACAO\"].replace({1:\"Sem problemas\", 2:\"Anulada\", 3:\"Cópia Texto Motivador\", 4:\"Em Branco\", 6:\"Fuga ao tema\", 7:\"Não atendimento ao tipo textual\", 8:\"Texto insuficiente\", 9:\"Parte desconectada\"}, inplace=True)\n",
    "\n",
    "#Até que série seu pai, ou o homem responsável por você, estudou?\n",
    "df['Q001'].replace({\n",
    "\"A\":\"Nunca estudou.\",\n",
    "\"B\":\"Não completou a 4ª série/5º ano do Ensino Fundamental.\",\n",
    "\"C\":\"Completou a 4ª série/5º ano, mas não completou a 8ª série/9º ano do Ensino Fundamental.\",\n",
    "\"D\":\"Completou a 8ª série/9º ano do Ensino Fundamental, mas não completou o Ensino Médio.\",\n",
    "\"E\":\"Completou o Ensino Médio, mas não completou a Faculdade.\",\n",
    "\"F\":\"Completou a Faculdade, mas não completou a Pós-graduação.\",\n",
    "\"G\":\"Completou a Pós-graduação.\",\n",
    "\"H\":\"Não sei.\"\n",
    "}, inplace=True)\n",
    "\n",
    "#Até que série sua mãe, ou a mulher responsável por você, estudou?\n",
    "df['Q002'].replace({\n",
    "\"A\":\"Nunca estudou.\",\n",
    "\"B\":\"Não completou a 4ª série/5º ano do Ensino Fundamental.\",\n",
    "\"C\":\"Completou a 4ª série/5º ano, mas não completou a 8ª série/9º ano do Ensino Fundamental.\",\n",
    "\"D\":\"Completou a 8ª série/9º ano do Ensino Fundamental, mas não completou o Ensino Médio.\",\n",
    "\"E\":\"Completou o Ensino Médio, mas não completou a Faculdade.\",\n",
    "\"F\":\"Completou a Faculdade, mas não completou a Pós-graduação.\",\n",
    "\"G\":\"Completou a Pós-graduação.\",\n",
    "\"H\":\"Não sei.\"\n",
    "}, inplace=True)\n",
    "\n",
    "#Qual é a renda mensal de sua família?\n",
    "df['Q006'].replace({\n",
    "\"A\":\"Nenhuma renda.\",\n",
    "\"B\":\"1 SM\",\n",
    "\"C\":\"1 a 1.5 SM\",\n",
    "\"D\":\"1.5 a 2 SM\",\n",
    "\"E\":\"2 a 2.5 SM\",\n",
    "\"F\":\"2.5 a 3 SM\",\n",
    "\"G\":\"3 a 4 SM\",\n",
    "\"H\":\"4 a 5 SM\",\n",
    "\"I\":\"5 a 6 SM\",\n",
    "\"J\":\"6 a 7 SM\",\n",
    "\"K\":\"7 a 8 SM\",\n",
    "\"L\":\"8 a 9 SM\",\n",
    "\"M\":\"9 a 10 SM\",\n",
    "\"N\":\"10 a 12 SM\",\n",
    "\"O\":\"12 a 15 SM\",\n",
    "\"P\":\"15 a 20 SM\",\n",
    "\"Q\":\"Mais de 20 SM\"\n",
    "}, inplace=True)\n",
    "\n",
    "#Na sua residência tem acesso à Internet? \n",
    "df['Q025'].replace({\"A\":\"Não\", \"B\":\"Sim\"}, inplace=True) \n",
    "\n",
    "print(\"Replaces prontos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro pronto\n"
     ]
    }
   ],
   "source": [
    "# Filtro  21202 Inscrições\n",
    "# Inscritos que residem em Porto Alegre\n",
    "# Fizeram a prova em Porto Alegre\n",
    "# Presença em todas as provas\n",
    "df_by_city = df.loc[((df['NO_MUNICIPIO_RESIDENCIA'] == 'Porto Alegre') &\n",
    "             (df['NO_MUNICIPIO_PROVA'] == 'Porto Alegre') &       \n",
    "             (df['TP_PRESENCA_CN'] == 'Presente na prova') &\n",
    "             (df['TP_PRESENCA_CH'] == 'Presente na prova') &\n",
    "             (df['TP_PRESENCA_LC'] == 'Presente na prova') &\n",
    "             (df['TP_PRESENCA_MT'] == 'Presente na prova'))]\n",
    "\n",
    "# x INSCRIÇÕES DE PORTO ALEGRE\n",
    "df = pd.DataFrame(df_by_city)\n",
    "\n",
    "print(\"Filtro pronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remoções 2 prontas\n"
     ]
    }
   ],
   "source": [
    "# deletando mais algumas colunas que não são importantes após o filtro ser realizado\n",
    "# devem ser feitas após o filtro\n",
    "del df['NO_MUNICIPIO_PROVA']\n",
    "del df['TP_PRESENCA_CN']\n",
    "del df['TP_PRESENCA_CH']\n",
    "del df['TP_PRESENCA_LC']\n",
    "del df['TP_PRESENCA_MT']\n",
    "del df['NO_MUNICIPIO_ESC']\n",
    "del df['SG_UF_ESC']\n",
    "del df['NO_MUNICIPIO_RESIDENCIA'] # variáveis constantes apontadas no pandas profiling\n",
    "del df['SG_UF_RESIDENCIA'] # variáveis constantes apontadas no pandas profiling\n",
    "del df['IN_CEGUEIRA'] # variáveis constantes apontadas no pandas profiling\n",
    "del df['IN_IDOSO'] # variáveis constantes apontadas no pandas profiling\n",
    "del df['SG_UF_PROVA'] # variáveis constantes apontadas no pandas profiling\n",
    "\n",
    "print(\"Remoções 2 prontas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar a função do pandas_profiling/describe.py\n",
    "\n",
    "# para pegar as seguintes infos:\n",
    "   # datatype\n",
    "   # min_val\n",
    "   # max_val\n",
    "# de cada coluna do data frame\n",
    "\n",
    "def table_data_format(df_orig):\n",
    "    metadata = []\n",
    "    df = df_orig\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        helper = {}\n",
    "        key = col\n",
    "        if len(key) > 15:\n",
    "            key = col[:15]\n",
    "\n",
    "        helper['ascend'] = 0\n",
    "        helper['name'] = key\n",
    "        if(df.dtypes[col] == \"object\"):\n",
    "            df[col].replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                                        \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "            helper['datatype'] = 'string'\n",
    "            helper['values'] = df[col].unique().tolist()\n",
    "        elif(df.dtypes[col] == \"int64\"):\n",
    "            helper['datatype'] = 'int'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        elif(df.dtypes[col] == \"float64\"):\n",
    "            helper['datatype'] = 'float'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        metadata.append(helper)\n",
    "\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "    data_array = []\n",
    "    for row in range(df.shape[0]):\n",
    "        aux = []\n",
    "        for col in range(df.shape[1]):\n",
    "            aux.append(df.iloc[row, col])\n",
    "        data_array.append(aux)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = table_data_format(df)\n",
    "\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_data_format(df_orig):\n",
    "    metadata = []\n",
    "    df = df_orig\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        helper = {}\n",
    "        key = col\n",
    "        if len(key) > 15:\n",
    "            key = col[:15]\n",
    "\n",
    "        helper['ascend'] = 0\n",
    "        helper['name'] = key\n",
    "        if(df.dtypes[col] == \"object\"):\n",
    "            df[col].replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                                        \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "            helper['datatype'] = 'string'\n",
    "            helper['values'] = df[col].unique().tolist()\n",
    "        elif(df.dtypes[col] == \"int64\"):\n",
    "            helper['datatype'] = 'int'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        elif(df.dtypes[col] == \"float64\"):\n",
    "            helper['datatype'] = 'float'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        metadata.append(helper)\n",
    "\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "    data_array = []\n",
    "    for row in range(df.shape[0]):\n",
    "        aux = []\n",
    "        for col in range(df.shape[1]):\n",
    "            aux.append(df.iloc[row, col])\n",
    "        data_array.append(aux)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = table_data_format(df)\n",
    "\n",
    "#data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar csv para gerar o data table viz\n",
    "path = r'C:\\Users\\Luis_Dutra\\3D Objects\\datasets\\enem\\enem_2019_for_table_viz.csv'\n",
    "\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os primeiros X valores do data frame\n",
    "linhas = 500\n",
    "df = df.head(linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>SG_UF_NASCIMENTO</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>...</th>\n",
       "      <th>NU_NOTA_CH</th>\n",
       "      <th>NU_NOTA_LC</th>\n",
       "      <th>NU_NOTA_MT</th>\n",
       "      <th>TP_LINGUA</th>\n",
       "      <th>TP_STATUS_REDACAO</th>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <th>Q001</th>\n",
       "      <th>Q002</th>\n",
       "      <th>Q006</th>\n",
       "      <th>Q025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39020</th>\n",
       "      <td>190001043648</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>2018</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>582.1</td>\n",
       "      <td>544.5</td>\n",
       "      <td>680.7</td>\n",
       "      <td>Espanhol</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>760.0</td>\n",
       "      <td>Completou a Pós-graduação.</td>\n",
       "      <td>Completou a Faculdade, mas não completou a Pós...</td>\n",
       "      <td>9 a 10 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680121</th>\n",
       "      <td>190001684765</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>Casado(a)/Mora com companheiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>Antes de 2007</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>538.5</td>\n",
       "      <td>546.8</td>\n",
       "      <td>367.3</td>\n",
       "      <td>Espanhol</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>640.0</td>\n",
       "      <td>Completou a 8ª série/9º ano do Ensino Fundamen...</td>\n",
       "      <td>Completou a 4ª série/5º ano, mas não completou...</td>\n",
       "      <td>1 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680130</th>\n",
       "      <td>190001684774</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>Não informado</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Estou cursando e concluirei o Ensino Médio em ...</td>\n",
       "      <td>Não informado</td>\n",
       "      <td>Pública</td>\n",
       "      <td>...</td>\n",
       "      <td>529.1</td>\n",
       "      <td>526.9</td>\n",
       "      <td>412.6</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>660.0</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>2.5 a 3 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680135</th>\n",
       "      <td>190001684779</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>2014</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>464.7</td>\n",
       "      <td>535.7</td>\n",
       "      <td>659.7</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Não completou a 4ª série/5º ano do Ensino Fund...</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>1 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680149</th>\n",
       "      <td>190001684793</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>2017</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>537.0</td>\n",
       "      <td>557.6</td>\n",
       "      <td>393.6</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>620.0</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>Completou a 8ª série/9º ano do Ensino Fundamen...</td>\n",
       "      <td>2 a 2.5 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685848</th>\n",
       "      <td>190001690492</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Estou cursando e concluirei o Ensino Médio em ...</td>\n",
       "      <td>Não informado</td>\n",
       "      <td>Pública</td>\n",
       "      <td>...</td>\n",
       "      <td>458.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>640.0</td>\n",
       "      <td>Não completou a 4ª série/5º ano do Ensino Fund...</td>\n",
       "      <td>Não completou a 4ª série/5º ano do Ensino Fund...</td>\n",
       "      <td>1 a 1.5 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685858</th>\n",
       "      <td>190001690502</td>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>Não informado</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>470.9</td>\n",
       "      <td>525.5</td>\n",
       "      <td>391.7</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>560.0</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>5 a 6 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685867</th>\n",
       "      <td>190001690511</td>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Estou cursando e concluirei o Ensino Médio em ...</td>\n",
       "      <td>Não informado</td>\n",
       "      <td>Pública</td>\n",
       "      <td>...</td>\n",
       "      <td>389.3</td>\n",
       "      <td>489.7</td>\n",
       "      <td>490.4</td>\n",
       "      <td>Espanhol</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>560.0</td>\n",
       "      <td>Não completou a 4ª série/5º ano do Ensino Fund...</td>\n",
       "      <td>Não completou a 4ª série/5º ano do Ensino Fund...</td>\n",
       "      <td>1 a 1.5 SM</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685868</th>\n",
       "      <td>190001690512</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Não declarado</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>SC</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>2018</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>666.9</td>\n",
       "      <td>611.2</td>\n",
       "      <td>705.4</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>640.0</td>\n",
       "      <td>Completou a Pós-graduação.</td>\n",
       "      <td>Completou a Faculdade, mas não completou a Pós...</td>\n",
       "      <td>15 a 20 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685873</th>\n",
       "      <td>190001690517</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Brasileiro(a)</td>\n",
       "      <td>RS</td>\n",
       "      <td>Já concluí o Ensino Médio</td>\n",
       "      <td>2015</td>\n",
       "      <td>Não Respondeu</td>\n",
       "      <td>...</td>\n",
       "      <td>569.3</td>\n",
       "      <td>647.9</td>\n",
       "      <td>598.7</td>\n",
       "      <td>Inglês</td>\n",
       "      <td>Sem problemas</td>\n",
       "      <td>680.0</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>Completou o Ensino Médio, mas não completou a ...</td>\n",
       "      <td>1 a 1.5 SM</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NU_INSCRICAO  NU_IDADE TP_SEXO                    TP_ESTADO_CIVIL  \\\n",
       "39020   190001043648        19       M                        Solteiro(a)   \n",
       "680121  190001684765        35       F  Casado(a)/Mora com companheiro(a)   \n",
       "680130  190001684774        18       F                      Não informado   \n",
       "680135  190001684779        24       M                        Solteiro(a)   \n",
       "680149  190001684793        20       F                        Solteiro(a)   \n",
       "...              ...       ...     ...                                ...   \n",
       "685848  190001690492        18       F                        Solteiro(a)   \n",
       "685858  190001690502        21       F                        Solteiro(a)   \n",
       "685867  190001690511        19       F                        Solteiro(a)   \n",
       "685868  190001690512        19       M                        Solteiro(a)   \n",
       "685873  190001690517        22       F                        Solteiro(a)   \n",
       "\n",
       "          TP_COR_RACA TP_NACIONALIDADE SG_UF_NASCIMENTO  \\\n",
       "39020           Parda    Brasileiro(a)               RS   \n",
       "680121         Branca    Brasileiro(a)               RS   \n",
       "680130         Branca    Brasileiro(a)               RS   \n",
       "680135         Branca    Brasileiro(a)               RS   \n",
       "680149         Branca    Brasileiro(a)               RS   \n",
       "...               ...              ...              ...   \n",
       "685848         Branca    Brasileiro(a)               RS   \n",
       "685858         Branca    Brasileiro(a)               RS   \n",
       "685867          Parda    Brasileiro(a)               RS   \n",
       "685868  Não declarado    Brasileiro(a)               SC   \n",
       "685873         Branca    Brasileiro(a)               RS   \n",
       "\n",
       "                                          TP_ST_CONCLUSAO TP_ANO_CONCLUIU  \\\n",
       "39020                           Já concluí o Ensino Médio            2018   \n",
       "680121                          Já concluí o Ensino Médio   Antes de 2007   \n",
       "680130  Estou cursando e concluirei o Ensino Médio em ...   Não informado   \n",
       "680135                          Já concluí o Ensino Médio            2014   \n",
       "680149                          Já concluí o Ensino Médio            2017   \n",
       "...                                                   ...             ...   \n",
       "685848  Estou cursando e concluirei o Ensino Médio em ...   Não informado   \n",
       "685858                          Já concluí o Ensino Médio   Não informado   \n",
       "685867  Estou cursando e concluirei o Ensino Médio em ...   Não informado   \n",
       "685868                          Já concluí o Ensino Médio            2018   \n",
       "685873                          Já concluí o Ensino Médio            2015   \n",
       "\n",
       "            TP_ESCOLA  ... NU_NOTA_CH NU_NOTA_LC NU_NOTA_MT TP_LINGUA  \\\n",
       "39020   Não Respondeu  ...      582.1      544.5      680.7  Espanhol   \n",
       "680121  Não Respondeu  ...      538.5      546.8      367.3  Espanhol   \n",
       "680130        Pública  ...      529.1      526.9      412.6    Inglês   \n",
       "680135  Não Respondeu  ...      464.7      535.7      659.7    Inglês   \n",
       "680149  Não Respondeu  ...      537.0      557.6      393.6    Inglês   \n",
       "...               ...  ...        ...        ...        ...       ...   \n",
       "685848        Pública  ...      458.0      569.0      560.0    Inglês   \n",
       "685858  Não Respondeu  ...      470.9      525.5      391.7    Inglês   \n",
       "685867        Pública  ...      389.3      489.7      490.4  Espanhol   \n",
       "685868  Não Respondeu  ...      666.9      611.2      705.4    Inglês   \n",
       "685873  Não Respondeu  ...      569.3      647.9      598.7    Inglês   \n",
       "\n",
       "       TP_STATUS_REDACAO NU_NOTA_REDACAO  \\\n",
       "39020      Sem problemas           760.0   \n",
       "680121     Sem problemas           640.0   \n",
       "680130     Sem problemas           660.0   \n",
       "680135     Sem problemas           800.0   \n",
       "680149     Sem problemas           620.0   \n",
       "...                  ...             ...   \n",
       "685848     Sem problemas           640.0   \n",
       "685858     Sem problemas           560.0   \n",
       "685867     Sem problemas           560.0   \n",
       "685868     Sem problemas           640.0   \n",
       "685873     Sem problemas           680.0   \n",
       "\n",
       "                                                     Q001  \\\n",
       "39020                          Completou a Pós-graduação.   \n",
       "680121  Completou a 8ª série/9º ano do Ensino Fundamen...   \n",
       "680130  Completou o Ensino Médio, mas não completou a ...   \n",
       "680135  Não completou a 4ª série/5º ano do Ensino Fund...   \n",
       "680149  Completou o Ensino Médio, mas não completou a ...   \n",
       "...                                                   ...   \n",
       "685848  Não completou a 4ª série/5º ano do Ensino Fund...   \n",
       "685858  Completou o Ensino Médio, mas não completou a ...   \n",
       "685867  Não completou a 4ª série/5º ano do Ensino Fund...   \n",
       "685868                         Completou a Pós-graduação.   \n",
       "685873  Completou o Ensino Médio, mas não completou a ...   \n",
       "\n",
       "                                                     Q002        Q006 Q025  \n",
       "39020   Completou a Faculdade, mas não completou a Pós...   9 a 10 SM  Sim  \n",
       "680121  Completou a 4ª série/5º ano, mas não completou...        1 SM  Sim  \n",
       "680130  Completou o Ensino Médio, mas não completou a ...  2.5 a 3 SM  Sim  \n",
       "680135  Completou o Ensino Médio, mas não completou a ...        1 SM  Sim  \n",
       "680149  Completou a 8ª série/9º ano do Ensino Fundamen...  2 a 2.5 SM  Sim  \n",
       "...                                                   ...         ...  ...  \n",
       "685848  Não completou a 4ª série/5º ano do Ensino Fund...  1 a 1.5 SM  Sim  \n",
       "685858  Completou o Ensino Médio, mas não completou a ...    5 a 6 SM  Sim  \n",
       "685867  Não completou a 4ª série/5º ano do Ensino Fund...  1 a 1.5 SM  Não  \n",
       "685868  Completou a Faculdade, mas não completou a Pós...  15 a 20 SM  Sim  \n",
       "685873  Completou o Ensino Médio, mas não completou a ...  1 a 1.5 SM  Sim  \n",
       "\n",
       "[400 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe a quantiade de linhas e colunas\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar: quantInsc = quantidade de linhas\n",
    "# Atualizar: quantColumns = quantidade de colunas\n",
    "\n",
    "quantInsc = 500 \n",
    "quantColumns = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsituindo missing values\n",
    "df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                       \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview salva!\n"
     ]
    }
   ],
   "source": [
    "# Salvando dataset antes de organizar para a visualizção\n",
    "# Para gerar relatório no pandas profiling\n",
    "path = r'C:\\Users\\Luis_Dutra\\3D Objects\\datasets\\enem\\enem_2019_preview_500_lines.csv'\n",
    "\n",
    "df.to_csv(path, index=False)\n",
    "\n",
    "print(\"preview salva!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um df para cada coluna do dataset\n",
    "df_col_id=df[['NU_INSCRICAO']]\n",
    "\n",
    "df_col_1=df[['NU_IDADE']]\n",
    "df_col_2=df[['TP_SEXO']]\n",
    "df_col_3=df[['TP_ESTADO_CIVIL']]\n",
    "df_col_4=df[['TP_COR_RACA']]\n",
    "df_col_5=df[['TP_NACIONALIDADE']]\n",
    "df_col_6=df[['SG_UF_NASCIMENTO']]\n",
    "df_col_7=df[['TP_ST_CONCLUSAO']]\n",
    "df_col_8=df[['TP_ANO_CONCLUIU']]\n",
    "df_col_9=df[['TP_ESCOLA']]\n",
    "df_col_10=df[['TP_ENSINO']]\n",
    "df_col_11=df[['IN_TREINEIRO']]\n",
    "df_col_12=df[['TP_DEPENDENCIA_ADM_ESC']]\n",
    "df_col_13=df[['TP_LOCALIZACAO_ESC']]\n",
    "df_col_14=df[['TP_SIT_FUNC_ESC']]\n",
    "df_col_15=df[['IN_SURDEZ']]\n",
    "df_col_16=df[['IN_SURDO_CEGUEIRA']]\n",
    "df_col_17=df[['IN_DEFICIENCIA_FISICA']]\n",
    "df_col_18=df[['IN_DEFICIENCIA_MENTAL']]\n",
    "df_col_19=df[['IN_DEFICIT_ATENCAO']]\n",
    "df_col_20=df[['IN_DISLEXIA']]\n",
    "df_col_21=df[['IN_DISCALCULIA']]\n",
    "df_col_22=df[['IN_AUTISMO']]\n",
    "df_col_23=df[['IN_GESTANTE']]\n",
    "df_col_24=df[['NU_NOTA_CN']]\n",
    "df_col_25=df[['NU_NOTA_CH']]\n",
    "df_col_26=df[['NU_NOTA_LC']]\n",
    "df_col_27=df[['NU_NOTA_MT']]\n",
    "df_col_28=df[['TP_LINGUA']]\n",
    "df_col_29=df[['TP_STATUS_REDACAO']]\n",
    "df_col_30=df[['NU_NOTA_REDACAO']]\n",
    "df_col_31=df[['Q001']]\n",
    "df_col_32=df[['Q002']]\n",
    "df_col_33=df[['Q006']]\n",
    "df_col_34=df[['Q025']]\n",
    "\n",
    "# df_col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatena a coluna NU_INSCRIÇÃO n vezes e renomeia a coluna para variable\n",
    "# Coluna variable pronta !\n",
    "\n",
    "df_variable = pd.concat([df_col_id] * quantColumns, ignore_index=True)\n",
    "\n",
    "df_variable = df_variable.rename(columns={'NU_INSCRICAO':'variable'})\n",
    "\n",
    "### df_variable pronto ###\n",
    "#df_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegando os 'x' primeiros valores de cada coluna e criando dataframes de valores\n",
    "\n",
    "values_col_1=df_col_1.head(quantInsc)\n",
    "values_col_2=df_col_2.head(quantInsc)\n",
    "values_col_3=df_col_3.head(quantInsc)\n",
    "values_col_4=df_col_4.head(quantInsc)\n",
    "values_col_5=df_col_5.head(quantInsc)\n",
    "values_col_6=df_col_6.head(quantInsc)\n",
    "values_col_7=df_col_7.head(quantInsc)\n",
    "values_col_8=df_col_8.head(quantInsc)\n",
    "values_col_9=df_col_9.head(quantInsc)\n",
    "values_col_10=df_col_10.head(quantInsc)\n",
    "values_col_11=df_col_11.head(quantInsc)\n",
    "values_col_12=df_col_12.head(quantInsc)\n",
    "values_col_13=df_col_13.head(quantInsc)\n",
    "values_col_14=df_col_14.head(quantInsc)\n",
    "values_col_15=df_col_15.head(quantInsc)\n",
    "values_col_16=df_col_16.head(quantInsc)\n",
    "values_col_17=df_col_17.head(quantInsc)\n",
    "values_col_18=df_col_18.head(quantInsc)\n",
    "values_col_19=df_col_19.head(quantInsc)\n",
    "values_col_20=df_col_20.head(quantInsc)\n",
    "values_col_21=df_col_21.head(quantInsc)\n",
    "values_col_22=df_col_22.head(quantInsc)\n",
    "values_col_23=df_col_23.head(quantInsc)\n",
    "values_col_24=df_col_24.head(quantInsc)\n",
    "values_col_25=df_col_25.head(quantInsc)\n",
    "values_col_26=df_col_26.head(quantInsc)\n",
    "values_col_27=df_col_27.head(quantInsc)\n",
    "values_col_28=df_col_28.head(quantInsc)\n",
    "values_col_29=df_col_29.head(quantInsc)\n",
    "values_col_30=df_col_30.head(quantInsc)\n",
    "values_col_31=df_col_31.head(quantInsc)\n",
    "values_col_32=df_col_32.head(quantInsc)\n",
    "values_col_33=df_col_33.head(quantInsc)\n",
    "values_col_34=df_col_34.head(quantInsc)\n",
    "\n",
    "#values_col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando a coluna dos dataframes de valores para value\n",
    "\n",
    "values_col_1=values_col_1.rename(columns={'NU_IDADE':'value'})\n",
    "values_col_2=values_col_2.rename(columns={'TP_SEXO':'value'})\n",
    "values_col_3=values_col_3.rename(columns={'TP_ESTADO_CIVIL':'value'})\n",
    "values_col_4=values_col_4.rename(columns={'TP_COR_RACA':'value'})\n",
    "values_col_5=values_col_5.rename(columns={'TP_NACIONALIDADE':'value'})\n",
    "values_col_6=values_col_6.rename(columns={'SG_UF_NASCIMENTO':'value'})\n",
    "values_col_7=values_col_7.rename(columns={'TP_ST_CONCLUSAO':'value'})\n",
    "values_col_8=values_col_8.rename(columns={'TP_ANO_CONCLUIU':'value'})\n",
    "values_col_9=values_col_9.rename(columns={'TP_ESCOLA':'value'})\n",
    "values_col_10=values_col_10.rename(columns={'TP_ENSINO':'value'})\n",
    "values_col_11=values_col_11.rename(columns={'IN_TREINEIRO':'value'})\n",
    "values_col_12=values_col_12.rename(columns={'TP_DEPENDENCIA_ADM_ESC':'value'})\n",
    "values_col_13=values_col_13.rename(columns={'TP_LOCALIZACAO_ESC':'value'})\n",
    "values_col_14=values_col_14.rename(columns={'TP_SIT_FUNC_ESC':'value'})\n",
    "values_col_15=values_col_15.rename(columns={'IN_SURDEZ':'value'})\n",
    "values_col_16=values_col_16.rename(columns={'IN_SURDO_CEGUEIRA':'value'})\n",
    "values_col_17=values_col_17.rename(columns={'IN_DEFICIENCIA_FISICA':'value'})\n",
    "values_col_18=values_col_18.rename(columns={'IN_DEFICIENCIA_MENTAL':'value'})\n",
    "values_col_19=values_col_19.rename(columns={'IN_DEFICIT_ATENCAO':'value'})\n",
    "values_col_20=values_col_20.rename(columns={'IN_DISLEXIA':'value'})\n",
    "values_col_21=values_col_21.rename(columns={'IN_DISCALCULIA':'value'})\n",
    "values_col_22=values_col_22.rename(columns={'IN_AUTISMO':'value'})\n",
    "values_col_23=values_col_23.rename(columns={'IN_GESTANTE':'value'})\n",
    "values_col_24=values_col_24.rename(columns={'NU_NOTA_CN':'value'})\n",
    "values_col_25=values_col_25.rename(columns={'NU_NOTA_CH':'value'})\n",
    "values_col_26=values_col_26.rename(columns={'NU_NOTA_LC':'value'})\n",
    "values_col_27=values_col_27.rename(columns={'NU_NOTA_MT':'value'})\n",
    "values_col_28=values_col_28.rename(columns={'TP_LINGUA':'value'})\n",
    "values_col_29=values_col_29.rename(columns={'TP_STATUS_REDACAO':'value'})\n",
    "values_col_30=values_col_30.rename(columns={'NU_NOTA_REDACAO':'value'})\n",
    "values_col_31=values_col_31.rename(columns={'Q001':'value'})\n",
    "values_col_32=values_col_32.rename(columns={'Q002':'value'})\n",
    "values_col_33=values_col_33.rename(columns={'Q006':'value'})\n",
    "values_col_34=values_col_34.rename(columns={'Q025':'value'})\n",
    "\n",
    "#values_col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenando os dataframes de valores em um único dataframe\n",
    "\n",
    "df_value=pd.concat([\n",
    "values_col_1,\n",
    "values_col_2,\n",
    "values_col_3,\n",
    "values_col_4,\n",
    "values_col_5,\n",
    "values_col_6,\n",
    "values_col_7,\n",
    "values_col_8,\n",
    "values_col_9,\n",
    "values_col_10,\n",
    "values_col_11,\n",
    "values_col_12,\n",
    "values_col_13,\n",
    "values_col_14,\n",
    "values_col_15,\n",
    "values_col_16,\n",
    "values_col_17,\n",
    "values_col_18,\n",
    "values_col_19,\n",
    "values_col_20,\n",
    "values_col_21,\n",
    "values_col_22,\n",
    "values_col_23,\n",
    "values_col_24,\n",
    "values_col_25,\n",
    "values_col_26,\n",
    "values_col_27,\n",
    "values_col_28,\n",
    "values_col_29,\n",
    "values_col_30,\n",
    "values_col_31,\n",
    "values_col_32,\n",
    "values_col_33,\n",
    "values_col_34], ignore_index=True)\n",
    "\n",
    "### df_value pronto ###\n",
    "#df_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataframe group\n",
    "\n",
    "df_col_1=pd.DataFrame({'group':['NU_IDADE']})\n",
    "df_col_2=pd.DataFrame({'group':['TP_SEXO']})\n",
    "df_col_3=pd.DataFrame({'group':['TP_ESTADO_CIVIL']})\n",
    "df_col_4=pd.DataFrame({'group':['TP_COR_RACA']})\n",
    "df_col_5=pd.DataFrame({'group':['TP_NACIONALIDADE']})\n",
    "df_col_6=pd.DataFrame({'group':['SG_UF_NASCIMENTO']})\n",
    "df_col_7=pd.DataFrame({'group':['TP_ST_CONCLUSAO']})\n",
    "df_col_8=pd.DataFrame({'group':['TP_ANO_CONCLUIU']})\n",
    "df_col_9=pd.DataFrame({'group':['TP_ESCOLA']})\n",
    "df_col_10=pd.DataFrame({'group':['TP_ENSINO']})\n",
    "df_col_11=pd.DataFrame({'group':['IN_TREINEIRO']})\n",
    "df_col_12=pd.DataFrame({'group':['TP_DEPENDENCIA_ADM_ESC']})\n",
    "df_col_13=pd.DataFrame({'group':['TP_LOCALIZACAO_ESC']})\n",
    "df_col_14=pd.DataFrame({'group':['TP_SIT_FUNC_ESC']})\n",
    "df_col_15=pd.DataFrame({'group':['IN_SURDEZ']})\n",
    "df_col_16=pd.DataFrame({'group':['IN_SURDO_CEGUEIRA']})\n",
    "df_col_17=pd.DataFrame({'group':['IN_DEFICIENCIA_FISICA']})\n",
    "df_col_18=pd.DataFrame({'group':['IN_DEFICIENCIA_MENTAL']})\n",
    "df_col_19=pd.DataFrame({'group':['IN_DEFICIT_ATENCAO']})\n",
    "df_col_20=pd.DataFrame({'group':['IN_DISLEXIA']})\n",
    "df_col_21=pd.DataFrame({'group':['IN_DISCALCULIA']})\n",
    "df_col_22=pd.DataFrame({'group':['IN_AUTISMO']})\n",
    "df_col_23=pd.DataFrame({'group':['IN_GESTANTE']})\n",
    "df_col_24=pd.DataFrame({'group':['NU_NOTA_CN']})\n",
    "df_col_25=pd.DataFrame({'group':['NU_NOTA_CH']})\n",
    "df_col_26=pd.DataFrame({'group':['NU_NOTA_LC']})\n",
    "df_col_27=pd.DataFrame({'group':['NU_NOTA_MT']})\n",
    "df_col_28=pd.DataFrame({'group':['TP_LINGUA']})\n",
    "df_col_29=pd.DataFrame({'group':['TP_STATUS_REDACAO']})\n",
    "df_col_30=pd.DataFrame({'group':['NU_NOTA_REDACAO']})\n",
    "df_col_31=pd.DataFrame({'group':['Q001']})\n",
    "df_col_32=pd.DataFrame({'group':['Q002']})\n",
    "df_col_33=pd.DataFrame({'group':['Q006']})\n",
    "df_col_34=pd.DataFrame({'group':['Q025']})\n",
    "\n",
    "# Concatenando cada linha do data frame de tipos de dados X vezes e criando um data frame para cada.\n",
    "df_column_rep_1=pd.concat([df_col_1]*quantInsc, ignore_index=True)\n",
    "df_column_rep_2=pd.concat([df_col_2]*quantInsc, ignore_index=True)\n",
    "df_column_rep_3=pd.concat([df_col_3]*quantInsc, ignore_index=True)\n",
    "df_column_rep_4=pd.concat([df_col_4]*quantInsc, ignore_index=True)\n",
    "df_column_rep_5=pd.concat([df_col_5]*quantInsc, ignore_index=True)\n",
    "df_column_rep_6=pd.concat([df_col_6]*quantInsc, ignore_index=True)\n",
    "df_column_rep_7=pd.concat([df_col_7]*quantInsc, ignore_index=True)\n",
    "df_column_rep_8=pd.concat([df_col_8]*quantInsc, ignore_index=True)\n",
    "df_column_rep_9=pd.concat([df_col_9]*quantInsc, ignore_index=True)\n",
    "df_column_rep_10=pd.concat([df_col_10]*quantInsc, ignore_index=True)\n",
    "df_column_rep_11=pd.concat([df_col_11]*quantInsc, ignore_index=True)\n",
    "df_column_rep_12=pd.concat([df_col_12]*quantInsc, ignore_index=True)\n",
    "df_column_rep_13=pd.concat([df_col_13]*quantInsc, ignore_index=True)\n",
    "df_column_rep_14=pd.concat([df_col_14]*quantInsc, ignore_index=True)\n",
    "df_column_rep_15=pd.concat([df_col_15]*quantInsc, ignore_index=True)\n",
    "df_column_rep_16=pd.concat([df_col_16]*quantInsc, ignore_index=True)\n",
    "df_column_rep_17=pd.concat([df_col_17]*quantInsc, ignore_index=True)\n",
    "df_column_rep_18=pd.concat([df_col_18]*quantInsc, ignore_index=True)\n",
    "df_column_rep_19=pd.concat([df_col_19]*quantInsc, ignore_index=True)\n",
    "df_column_rep_20=pd.concat([df_col_20]*quantInsc, ignore_index=True)\n",
    "df_column_rep_21=pd.concat([df_col_21]*quantInsc, ignore_index=True)\n",
    "df_column_rep_22=pd.concat([df_col_22]*quantInsc, ignore_index=True)\n",
    "df_column_rep_23=pd.concat([df_col_23]*quantInsc, ignore_index=True)\n",
    "df_column_rep_24=pd.concat([df_col_24]*quantInsc, ignore_index=True)\n",
    "df_column_rep_25=pd.concat([df_col_25]*quantInsc, ignore_index=True)\n",
    "df_column_rep_26=pd.concat([df_col_26]*quantInsc, ignore_index=True)\n",
    "df_column_rep_27=pd.concat([df_col_27]*quantInsc, ignore_index=True)\n",
    "df_column_rep_28=pd.concat([df_col_28]*quantInsc, ignore_index=True)\n",
    "df_column_rep_29=pd.concat([df_col_29]*quantInsc, ignore_index=True)\n",
    "df_column_rep_30=pd.concat([df_col_30]*quantInsc, ignore_index=True)\n",
    "df_column_rep_31=pd.concat([df_col_31]*quantInsc, ignore_index=True)\n",
    "df_column_rep_32=pd.concat([df_col_32]*quantInsc, ignore_index=True)\n",
    "df_column_rep_33=pd.concat([df_col_33]*quantInsc, ignore_index=True)\n",
    "df_column_rep_34=pd.concat([df_col_34]*quantInsc, ignore_index=True)\n",
    "\n",
    "df_group = pd.concat([\n",
    "df_column_rep_1,\n",
    "df_column_rep_2,\n",
    "df_column_rep_3,\n",
    "df_column_rep_4,\n",
    "df_column_rep_5,\n",
    "df_column_rep_6,\n",
    "df_column_rep_7,\n",
    "df_column_rep_8,\n",
    "df_column_rep_9,\n",
    "df_column_rep_10,\n",
    "df_column_rep_11,\n",
    "df_column_rep_12,\n",
    "df_column_rep_13,\n",
    "df_column_rep_14,\n",
    "df_column_rep_15,\n",
    "df_column_rep_16,\n",
    "df_column_rep_17,\n",
    "df_column_rep_18,\n",
    "df_column_rep_19,\n",
    "df_column_rep_20,\n",
    "df_column_rep_21,\n",
    "df_column_rep_22,\n",
    "df_column_rep_23,\n",
    "df_column_rep_24,\n",
    "df_column_rep_25,\n",
    "df_column_rep_26,\n",
    "df_column_rep_27,\n",
    "df_column_rep_28,\n",
    "df_column_rep_29,\n",
    "df_column_rep_30,\n",
    "df_column_rep_31,\n",
    "df_column_rep_32,\n",
    "df_column_rep_33,\n",
    "df_column_rep_34], ignore_index=True)\n",
    "\n",
    "#df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATUALIZAR DATA TYPE\n",
    "# criando o dataframe com os tipos de dados de cada coluna\n",
    "\n",
    "# Criando o array de dados com o tipo de dado de cada coluna\n",
    "data_type = {'datatype' : [\n",
    "'int',\n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'float',  \n",
    "'float',  \n",
    "'float',  \n",
    "'float',  \n",
    "'string', \n",
    "'string', \n",
    "'float',  \n",
    "'string', \n",
    "'string', \n",
    "'string', \n",
    "'string']}\n",
    "\n",
    "# Transformando em um data frame\n",
    "df_type = pd.DataFrame(data_type, columns = ['datatype'])\n",
    "\n",
    "# Concatenando cada linha do data frame de tipos de dados X vezes e criando um data frame para cada.\n",
    "df_datatype0 = pd.concat([df_type.loc[[0]]]*quantInsc, ignore_index=True)\n",
    "df_datatype1 = pd.concat([df_type.loc[[1]]]*quantInsc, ignore_index=True)\n",
    "df_datatype2 = pd.concat([df_type.loc[[2]]]*quantInsc, ignore_index=True)\n",
    "df_datatype3 = pd.concat([df_type.loc[[3]]]*quantInsc, ignore_index=True)\n",
    "df_datatype4 = pd.concat([df_type.loc[[4]]]*quantInsc, ignore_index=True)\n",
    "df_datatype5 = pd.concat([df_type.loc[[5]]]*quantInsc, ignore_index=True)\n",
    "df_datatype6 = pd.concat([df_type.loc[[6]]]*quantInsc, ignore_index=True)\n",
    "df_datatype7 = pd.concat([df_type.loc[[7]]]*quantInsc, ignore_index=True)\n",
    "df_datatype8 = pd.concat([df_type.loc[[8]]]*quantInsc, ignore_index=True)\n",
    "df_datatype9 = pd.concat([df_type.loc[[9]]]*quantInsc, ignore_index=True)\n",
    "df_datatype10 = pd.concat([df_type.loc[[10]]]*quantInsc, ignore_index=True)\n",
    "df_datatype11 = pd.concat([df_type.loc[[11]]]*quantInsc, ignore_index=True)\n",
    "df_datatype12 = pd.concat([df_type.loc[[12]]]*quantInsc, ignore_index=True)\n",
    "df_datatype13 = pd.concat([df_type.loc[[13]]]*quantInsc, ignore_index=True)\n",
    "df_datatype14 = pd.concat([df_type.loc[[14]]]*quantInsc, ignore_index=True)\n",
    "df_datatype15 = pd.concat([df_type.loc[[15]]]*quantInsc, ignore_index=True)\n",
    "df_datatype16 = pd.concat([df_type.loc[[16]]]*quantInsc, ignore_index=True)\n",
    "df_datatype17 = pd.concat([df_type.loc[[17]]]*quantInsc, ignore_index=True)\n",
    "df_datatype18 = pd.concat([df_type.loc[[18]]]*quantInsc, ignore_index=True)\n",
    "df_datatype19 = pd.concat([df_type.loc[[19]]]*quantInsc, ignore_index=True)\n",
    "df_datatype20 = pd.concat([df_type.loc[[20]]]*quantInsc, ignore_index=True)\n",
    "df_datatype21 = pd.concat([df_type.loc[[21]]]*quantInsc, ignore_index=True)\n",
    "df_datatype22 = pd.concat([df_type.loc[[22]]]*quantInsc, ignore_index=True)\n",
    "df_datatype23 = pd.concat([df_type.loc[[23]]]*quantInsc, ignore_index=True)\n",
    "df_datatype24 = pd.concat([df_type.loc[[24]]]*quantInsc, ignore_index=True)\n",
    "df_datatype25 = pd.concat([df_type.loc[[25]]]*quantInsc, ignore_index=True)\n",
    "df_datatype26 = pd.concat([df_type.loc[[26]]]*quantInsc, ignore_index=True)\n",
    "df_datatype27 = pd.concat([df_type.loc[[27]]]*quantInsc, ignore_index=True)\n",
    "df_datatype28 = pd.concat([df_type.loc[[28]]]*quantInsc, ignore_index=True)\n",
    "df_datatype29 = pd.concat([df_type.loc[[29]]]*quantInsc, ignore_index=True)\n",
    "df_datatype30 = pd.concat([df_type.loc[[30]]]*quantInsc, ignore_index=True)\n",
    "df_datatype31 = pd.concat([df_type.loc[[31]]]*quantInsc, ignore_index=True)\n",
    "df_datatype32 = pd.concat([df_type.loc[[32]]]*quantInsc, ignore_index=True)\n",
    "df_datatype33 = pd.concat([df_type.loc[[33]]]*quantInsc, ignore_index=True)\n",
    "\n",
    "# concatenando todas os data frames em um único data frame\n",
    "df_datatype = pd.concat([\n",
    "df_datatype0,\n",
    "df_datatype1,\n",
    "df_datatype2,\n",
    "df_datatype3,\n",
    "df_datatype4,\n",
    "df_datatype5,\n",
    "df_datatype6,\n",
    "df_datatype7,\n",
    "df_datatype8,\n",
    "df_datatype9,\n",
    "df_datatype10,\n",
    "df_datatype11,\n",
    "df_datatype12,\n",
    "df_datatype13,\n",
    "df_datatype14,\n",
    "df_datatype15,\n",
    "df_datatype16,\n",
    "df_datatype17,\n",
    "df_datatype18,\n",
    "df_datatype19,\n",
    "df_datatype20,\n",
    "df_datatype21,\n",
    "df_datatype22,\n",
    "df_datatype23,\n",
    "df_datatype24,\n",
    "df_datatype25,\n",
    "df_datatype26,\n",
    "df_datatype27,\n",
    "df_datatype28,\n",
    "df_datatype29,\n",
    "df_datatype30,\n",
    "df_datatype31,\n",
    "df_datatype32,\n",
    "df_datatype33], ignore_index=True)\n",
    "\n",
    "### df_datatype PRONTO ###\n",
    "#df_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATUALIZAR MIN_VAL\n",
    "# Criando dataframe com os valores minimos de cada coluna\n",
    "\n",
    "# Criando array de dados dos valores minimos de cada coluna\n",
    "data_min={'min_val':[\n",
    "13,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0.0,\n",
    "0.0,\n",
    "0.0,\n",
    "0.0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1]} \n",
    "\n",
    "# Transformando em data frame\n",
    "df_min = pd.DataFrame(data_min, columns = ['min_val'])\n",
    "\n",
    "# Concatenando cada linha do data frame de valore minimos dados X vezes e criando um data frame para cada.\n",
    "df_data_min0 = pd.concat([df_min.loc[[0]]]*quantInsc, ignore_index=True)\n",
    "df_data_min1 = pd.concat([df_min.loc[[1]]]*quantInsc, ignore_index=True)\n",
    "df_data_min2 = pd.concat([df_min.loc[[2]]]*quantInsc, ignore_index=True)\n",
    "df_data_min3 = pd.concat([df_min.loc[[3]]]*quantInsc, ignore_index=True)\n",
    "df_data_min4 = pd.concat([df_min.loc[[4]]]*quantInsc, ignore_index=True)\n",
    "df_data_min5 = pd.concat([df_min.loc[[5]]]*quantInsc, ignore_index=True)\n",
    "df_data_min6 = pd.concat([df_min.loc[[6]]]*quantInsc, ignore_index=True)\n",
    "df_data_min7 = pd.concat([df_min.loc[[7]]]*quantInsc, ignore_index=True)\n",
    "df_data_min8 = pd.concat([df_min.loc[[8]]]*quantInsc, ignore_index=True)\n",
    "df_data_min9 = pd.concat([df_min.loc[[9]]]*quantInsc, ignore_index=True)\n",
    "df_data_min10 = pd.concat([df_min.loc[[10]]]*quantInsc, ignore_index=True)\n",
    "df_data_min11 = pd.concat([df_min.loc[[11]]]*quantInsc, ignore_index=True)\n",
    "df_data_min12 = pd.concat([df_min.loc[[12]]]*quantInsc, ignore_index=True)\n",
    "df_data_min13 = pd.concat([df_min.loc[[13]]]*quantInsc, ignore_index=True)\n",
    "df_data_min14 = pd.concat([df_min.loc[[14]]]*quantInsc, ignore_index=True)\n",
    "df_data_min15 = pd.concat([df_min.loc[[15]]]*quantInsc, ignore_index=True)\n",
    "df_data_min16 = pd.concat([df_min.loc[[16]]]*quantInsc, ignore_index=True)\n",
    "df_data_min17 = pd.concat([df_min.loc[[17]]]*quantInsc, ignore_index=True)\n",
    "df_data_min18 = pd.concat([df_min.loc[[18]]]*quantInsc, ignore_index=True)\n",
    "df_data_min19 = pd.concat([df_min.loc[[19]]]*quantInsc, ignore_index=True)\n",
    "df_data_min20 = pd.concat([df_min.loc[[20]]]*quantInsc, ignore_index=True)\n",
    "df_data_min21 = pd.concat([df_min.loc[[21]]]*quantInsc, ignore_index=True)\n",
    "df_data_min22 = pd.concat([df_min.loc[[22]]]*quantInsc, ignore_index=True)\n",
    "df_data_min23 = pd.concat([df_min.loc[[23]]]*quantInsc, ignore_index=True)\n",
    "df_data_min24 = pd.concat([df_min.loc[[24]]]*quantInsc, ignore_index=True)\n",
    "df_data_min25 = pd.concat([df_min.loc[[25]]]*quantInsc, ignore_index=True)\n",
    "df_data_min26 = pd.concat([df_min.loc[[26]]]*quantInsc, ignore_index=True)\n",
    "df_data_min27 = pd.concat([df_min.loc[[27]]]*quantInsc, ignore_index=True)\n",
    "df_data_min28 = pd.concat([df_min.loc[[28]]]*quantInsc, ignore_index=True)\n",
    "df_data_min29 = pd.concat([df_min.loc[[29]]]*quantInsc, ignore_index=True)\n",
    "df_data_min30 = pd.concat([df_min.loc[[30]]]*quantInsc, ignore_index=True)\n",
    "df_data_min31 = pd.concat([df_min.loc[[31]]]*quantInsc, ignore_index=True)\n",
    "df_data_min32 = pd.concat([df_min.loc[[32]]]*quantInsc, ignore_index=True)\n",
    "df_data_min33 = pd.concat([df_min.loc[[33]]]*quantInsc, ignore_index=True)\n",
    "\n",
    "# Concatenando os data frames de valores minimos em um unico data frame\n",
    "df_min = pd.concat([\n",
    "df_data_min0,\n",
    "df_data_min1,\n",
    "df_data_min2,\n",
    "df_data_min3,\n",
    "df_data_min4,\n",
    "df_data_min5,\n",
    "df_data_min6,\n",
    "df_data_min7,\n",
    "df_data_min8,\n",
    "df_data_min9,\n",
    "df_data_min10,\n",
    "df_data_min11,\n",
    "df_data_min12,\n",
    "df_data_min13,\n",
    "df_data_min14,\n",
    "df_data_min15,\n",
    "df_data_min16,\n",
    "df_data_min17,\n",
    "df_data_min18,\n",
    "df_data_min19,\n",
    "df_data_min20,\n",
    "df_data_min21,\n",
    "df_data_min22,\n",
    "df_data_min23,\n",
    "df_data_min24,\n",
    "df_data_min25,\n",
    "df_data_min26,\n",
    "df_data_min27,\n",
    "df_data_min28,\n",
    "df_data_min29,\n",
    "df_data_min30,\n",
    "df_data_min31,\n",
    "df_data_min32,\n",
    "df_data_min33\n",
    "], ignore_index=True)\n",
    "\n",
    "#df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATUALIZAR MAX_VAL\n",
    "#Criando um dataframe com os valores maximos de cada coluna\n",
    "\n",
    "# Criando o array de dados\n",
    "data_max = {'max_val' : [\n",
    "77,\n",
    "2,\n",
    "5,\n",
    "6,\n",
    "5,\n",
    "27,\n",
    "4,\n",
    "14,\n",
    "3,\n",
    "2,\n",
    "2,\n",
    "4,\n",
    "2,\n",
    "3,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "2,\n",
    "793.1,\n",
    "784.1,\n",
    "731.2,\n",
    "985.5,\n",
    "2,\n",
    "8,\n",
    "980.0,\n",
    "8,\n",
    "8,\n",
    "17,\n",
    "2]}\n",
    "\n",
    "# Transformando em data frame\n",
    "df_max = pd.DataFrame(data_max, columns = ['max_val'])\n",
    "\n",
    "# Concatenando cada linha do data frame de valore máximos dados X vezes e criando um data frame para cada. \n",
    "df_data_max0 = pd.concat([df_max.loc[[0]]]*quantInsc, ignore_index=True)\n",
    "df_data_max1 = pd.concat([df_max.loc[[1]]]*quantInsc, ignore_index=True)\n",
    "df_data_max2 = pd.concat([df_max.loc[[2]]]*quantInsc, ignore_index=True)\n",
    "df_data_max3 = pd.concat([df_max.loc[[3]]]*quantInsc, ignore_index=True)\n",
    "df_data_max4 = pd.concat([df_max.loc[[4]]]*quantInsc, ignore_index=True)\n",
    "df_data_max5 = pd.concat([df_max.loc[[5]]]*quantInsc, ignore_index=True)\n",
    "df_data_max6 = pd.concat([df_max.loc[[6]]]*quantInsc, ignore_index=True)\n",
    "df_data_max7 = pd.concat([df_max.loc[[7]]]*quantInsc, ignore_index=True)\n",
    "df_data_max8 = pd.concat([df_max.loc[[8]]]*quantInsc, ignore_index=True)\n",
    "df_data_max9 = pd.concat([df_max.loc[[9]]]*quantInsc, ignore_index=True)\n",
    "df_data_max10 = pd.concat([df_max.loc[[10]]]*quantInsc, ignore_index=True)\n",
    "df_data_max11 = pd.concat([df_max.loc[[11]]]*quantInsc, ignore_index=True)\n",
    "df_data_max12 = pd.concat([df_max.loc[[12]]]*quantInsc, ignore_index=True)\n",
    "df_data_max13 = pd.concat([df_max.loc[[13]]]*quantInsc, ignore_index=True)\n",
    "df_data_max14 = pd.concat([df_max.loc[[14]]]*quantInsc, ignore_index=True)\n",
    "df_data_max15 = pd.concat([df_max.loc[[15]]]*quantInsc, ignore_index=True)\n",
    "df_data_max16 = pd.concat([df_max.loc[[16]]]*quantInsc, ignore_index=True)\n",
    "df_data_max17 = pd.concat([df_max.loc[[17]]]*quantInsc, ignore_index=True)\n",
    "df_data_max18 = pd.concat([df_max.loc[[18]]]*quantInsc, ignore_index=True)\n",
    "df_data_max19 = pd.concat([df_max.loc[[19]]]*quantInsc, ignore_index=True)\n",
    "df_data_max20 = pd.concat([df_max.loc[[20]]]*quantInsc, ignore_index=True)\n",
    "df_data_max21 = pd.concat([df_max.loc[[21]]]*quantInsc, ignore_index=True)\n",
    "df_data_max22 = pd.concat([df_max.loc[[22]]]*quantInsc, ignore_index=True)\n",
    "df_data_max23 = pd.concat([df_max.loc[[23]]]*quantInsc, ignore_index=True)\n",
    "df_data_max24 = pd.concat([df_max.loc[[24]]]*quantInsc, ignore_index=True)\n",
    "df_data_max25 = pd.concat([df_max.loc[[25]]]*quantInsc, ignore_index=True)\n",
    "df_data_max26 = pd.concat([df_max.loc[[26]]]*quantInsc, ignore_index=True)\n",
    "df_data_max27 = pd.concat([df_max.loc[[27]]]*quantInsc, ignore_index=True)\n",
    "df_data_max28 = pd.concat([df_max.loc[[28]]]*quantInsc, ignore_index=True)\n",
    "df_data_max29 = pd.concat([df_max.loc[[29]]]*quantInsc, ignore_index=True)\n",
    "df_data_max30 = pd.concat([df_max.loc[[30]]]*quantInsc, ignore_index=True)\n",
    "df_data_max31 = pd.concat([df_max.loc[[31]]]*quantInsc, ignore_index=True)\n",
    "df_data_max32 = pd.concat([df_max.loc[[32]]]*quantInsc, ignore_index=True)\n",
    "df_data_max33 = pd.concat([df_max.loc[[33]]]*quantInsc, ignore_index=True)\n",
    "\n",
    "# Concatenando os data frames de valores máximos em um unico data frame\n",
    "df_max = pd.concat([\n",
    "df_data_max0,\n",
    "df_data_max1,\n",
    "df_data_max2,\n",
    "df_data_max3,\n",
    "df_data_max4,\n",
    "df_data_max5,\n",
    "df_data_max6,\n",
    "df_data_max7,\n",
    "df_data_max8,\n",
    "df_data_max9,\n",
    "df_data_max10,\n",
    "df_data_max11,\n",
    "df_data_max12,\n",
    "df_data_max13,\n",
    "df_data_max14,\n",
    "df_data_max15,\n",
    "df_data_max16,\n",
    "df_data_max17,\n",
    "df_data_max18,\n",
    "df_data_max19,\n",
    "df_data_max20,\n",
    "df_data_max21,\n",
    "df_data_max22,\n",
    "df_data_max23,\n",
    "df_data_max24,\n",
    "df_data_max25,\n",
    "df_data_max26,\n",
    "df_data_max27,\n",
    "df_data_max28,\n",
    "df_data_max29,\n",
    "df_data_max30,\n",
    "df_data_max31,\n",
    "df_data_max32,\n",
    "df_data_max33], ignore_index=True)\n",
    "\n",
    "#df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#União dos dataframes\n",
    "df_enem = pd.DataFrame(df_group)\n",
    "\n",
    "df_enem.insert(1, \"variable\", df_variable, True)\n",
    "\n",
    "df_enem.insert(2, \"value\", df_value, True)\n",
    "\n",
    "df_enem.insert(3, \"datatype\", df_datatype, True)\n",
    "\n",
    "df_enem.insert(4, \"min_val\", df_min, True)\n",
    "\n",
    "df_enem.insert(5, \"max_val\", df_max, True)\n",
    "\n",
    "#df_enem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanvando o dataset criado\n",
    "\n",
    "path = r'C:\\Users\\Luis_Dutra\\3D Objects\\datasets\\enem\\enem_2019_by_city_poa_formatted_with_500_lines.csv'\n",
    "\n",
    "df_enem.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
